{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to clean dataframes\n",
    "I created a function to clean the \"df_pin\" DataFrame, it can encapsulate the cleaning steps into a single function. \n",
    "\n",
    "Also I created an error handling to the function, it can use a try-except block to catch any potential errors that may occur during the cleaning process. Here's the function with error handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Clean the DataFrame that contains information about Pinterest posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To clean the df_pin DataFrame you should perform the following transformations:\n",
    "\n",
    "- Replace empty entries and entries with no relevant data in each column with Nones\n",
    "- Perform the necessary transformations on the follower_count to ensure every entry is a number. Make sure the data type of this column is an int.\n",
    "- Ensure that each column containing numeric data has a numeric data type\n",
    "- Clean the data in the save_location column to include only the save location path\n",
    "- Rename the index column to ind.\n",
    "- Reorder the DataFrame columns to have the following column order:\n",
    "  - ind\n",
    "  - unique_id\n",
    "  - title\n",
    "  - description\n",
    "  - follower_count\n",
    "  - poster_name\n",
    "  - tag_list\n",
    "  - is_image_or_video\n",
    "  - image_src\n",
    "  - save_location\n",
    "  - category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b08ec3f-0826-4dc2-8499-c453008e0c28",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace\n",
    "from pyspark.sql.types import IntegerType, LongType\n",
    "\n",
    "def clean_pin_dataframe(df_pin):\n",
    "    \"\"\"\n",
    "    Clean the DataFrame that contains information about Pinterest posts.\n",
    "\n",
    "    Parameters:\n",
    "    df_pin (DataFrame): DataFrame containing Pinterest posts data.\n",
    "\n",
    "    Returns:\n",
    "    df_pin_cleaned (DataFrame): Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Replace empty entries and entries with no relevant data in each column with None\n",
    "        df_pin_cleaned = df_pin.fillna(\"None\")\n",
    "\n",
    "        # Replace \"k\" with \"000\" and cast to integer for follower_count column\n",
    "        df_pin_cleaned = df_pin_cleaned.withColumn(\"follower_count\", \n",
    "                                                   regexp_replace(col(\"follower_count\"), \"k\", \"000\").cast(IntegerType()))\n",
    "\n",
    "        # Cast downloaded column to IntegerType\n",
    "        df_pin_cleaned = df_pin_cleaned.withColumn(\"downloaded\", df_pin_cleaned[\"downloaded\"].cast(IntegerType()))\n",
    "\n",
    "        # Cast index column to LongType\n",
    "        df_pin_cleaned = df_pin_cleaned.withColumn(\"index\", df_pin_cleaned[\"index\"].cast(LongType()))\n",
    "\n",
    "        # Rename index column to ind\n",
    "        df_pin_cleaned = df_pin_cleaned.withColumnRenamed(\"index\", \"ind\")\n",
    "\n",
    "        # Reorder the DataFrame columns\n",
    "        df_pin_cleaned = df_pin_cleaned.select(\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\", \n",
    "                                               \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\", \n",
    "                                               \"save_location\", \"category\")\n",
    "\n",
    "        return df_pin_cleaned\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data cleaning: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then call this function passing the \"df_pin\" DataFrame as an argument to clean it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d45688e-9f38-42a4-b200-c272ec89a8ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+\n",
       "  ind|           unique_id|               title|         description|follower_count|         poster_name|            tag_list|is_image_or_video|           image_src|       save_location|      category|\n",
       "+-----+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+\n",
       "10138|927c4658-cc3f-4b9...|14 Amazing Things...|This Costa Rica i...|         10000|Wanderlust Chloe ...|Costa Rica Travel...|            image|https://i.pinimg....|        /data/travel|        travel|\n",
       " 3156|fa6e31a4-18c2-4ec...|Handprint Reindee...|This post may con...|        892000|Michelle {CraftyM...|Christmas Gifts F...|            image|https://i.pinimg....|/data/diy-and-crafts|diy-and-crafts|\n",
       " 5395|71f72304-3708-45f...|So startest du mi...|Der #Vermögensauf...|          3000|DIVDepot – Geld s...|Money Saving Chal...|            image|https://i.pinimg....|       /data/finance|       finance|\n",
       " 5494|8fb2af68-543b-463...|Dave Ramsey&#39;s 7 B...|If you love budge...|         26000|Living Low Key | ...|Financial Peace,F...|            image|https://i.pinimg....|       /data/finance|       finance|\n",
       " 2418|da8745a6-5160-46c...|100 DIY Christmas...|Here are the best...|        500000|            HikenDip|Farmhouse Christm...|            image|https://i.pinimg....|     /data/christmas|     christmas|\n",
       " 1611|051e231c-7509-437...|Over The Years, P...|[PaidLink] It&#39;s m...|            22|    Hair Accessories|Natural Beauty Ti...|            image|https://i.pinimg....|        /data/beauty|        beauty|\n",
       " 3813|49f7dfe7-2e5a-403...|Fun Interactive D...|Tired of Google C...|          9000|Science of Curiosity|Google Classroom,...|            image|https://i.pinimg....|     /data/education|     education|\n",
       " 7922|a584581c-1b38-473...|45 Top Life Quote...|summcoco gives yo...|        306000|Sumcoco | Decor I...|Life Quotes Love,...|            image|https://i.pinimg....|        /data/quotes|        quotes|\n",
       " 1643|41be1bcd-1ead-476...|White and Gold Ch...|Connecticut life ...|         84000|      Lauren McBride|Christmas Dining ...|            image|https://i.pinimg....|     /data/christmas|     christmas|\n",
       " 5091|43459535-64e9-48a...|Buying Your First...|Buying your first...|           223|Edwin | Cash The ...|Paying Off Car Lo...|            image|https://i.pinimg....|       /data/finance|       finance|\n",
       " 9979|2b2abc85-fc51-481...|Paris in the Summ...|Are you traveling...|          3000|     Petite in Paris|Torre Eiffel Pari...|            image|https://i.pinimg....|        /data/travel|        travel|\n",
       " 3032|208b07bc-e042-4e8...|   Puffy Ghost Craft|This ghost craft ...|         56000|       Thriving Home|Halloween Arts An...|            video|https://i.pinimg....|/data/diy-and-crafts|diy-and-crafts|\n",
       " 6809|f8ca698f-abfc-4b6...|It&#39;s Time to Ditc...|It&#39;s safe to assu...|        383000|        Suburban Men|Business Casual D...|            image|https://i.pinimg....|  /data/mens-fashion|  mens-fashion|\n",
       " 3644|cde2b4e2-7711-4a8...|More Amazon Must ...|Amazon is a teach...|         41000|Teach Create Moti...|Classroom Hacks,5...|            image|https://i.pinimg....|     /data/education|     education|\n",
       " 6575|15c45907-657e-439...|Affordable Farmho...|Believe it or not...|         31000| Maria Louise Design|Farmhouse Remodel...|            image|https://i.pinimg....|    /data/home-decor|    home-decor|\n",
       " 6145|82e13a07-db99-43a...|HOLIDAY MANTLE DE...|Holiday mantle de...|         83000|     Stylin by Aylin|Winter Home Decor...|            image|https://i.pinimg....|    /data/home-decor|    home-decor|\n",
       " 6145|82e13a07-db99-43a...|HOLIDAY MANTLE DE...|Holiday mantle de...|         83000|     Stylin by Aylin|Winter Home Decor...|            image|https://i.pinimg....|    /data/home-decor|    home-decor|\n",
       "    4|55abcd28-bda1-445...|Mexican Artist Us...|Mexican artist En...|          null|         Bored Panda|Girl Drawing Sket...|            image|https://i.pinimg....|           /data/art|           art|\n",
       " 4315|21b59ba9-829d-4c3...|Podcasts for Teac...|Podcasts for Teac...|         25000|        Math Giraffe|Middle School Cla...|            image|https://i.pinimg....|     /data/education|     education|\n",
       " 5069|b75b6f87-deb3-444...|The Vault: Curate...|Sacramento Califo...|          null|     Style Me Pretty|60th Anniversary ...|            image|https://i.pinimg....|/data/event-planning|event-planning|\n",
       "+-----+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-----+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+\n|  ind|           unique_id|               title|         description|follower_count|         poster_name|            tag_list|is_image_or_video|           image_src|       save_location|      category|\n+-----+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+\n|10138|927c4658-cc3f-4b9...|14 Amazing Things...|This Costa Rica i...|         10000|Wanderlust Chloe ...|Costa Rica Travel...|            image|https://i.pinimg....|        /data/travel|        travel|\n| 3156|fa6e31a4-18c2-4ec...|Handprint Reindee...|This post may con...|        892000|Michelle {CraftyM...|Christmas Gifts F...|            image|https://i.pinimg....|/data/diy-and-crafts|diy-and-crafts|\n| 5395|71f72304-3708-45f...|So startest du mi...|Der #Vermögensauf...|          3000|DIVDepot – Geld s...|Money Saving Chal...|            image|https://i.pinimg....|       /data/finance|       finance|\n| 5494|8fb2af68-543b-463...|Dave Ramsey&#39;s 7 B...|If you love budge...|         26000|Living Low Key | ...|Financial Peace,F...|            image|https://i.pinimg....|       /data/finance|       finance|\n| 2418|da8745a6-5160-46c...|100 DIY Christmas...|Here are the best...|        500000|            HikenDip|Farmhouse Christm...|            image|https://i.pinimg....|     /data/christmas|     christmas|\n| 1611|051e231c-7509-437...|Over The Years, P...|[PaidLink] It&#39;s m...|            22|    Hair Accessories|Natural Beauty Ti...|            image|https://i.pinimg....|        /data/beauty|        beauty|\n| 3813|49f7dfe7-2e5a-403...|Fun Interactive D...|Tired of Google C...|          9000|Science of Curiosity|Google Classroom,...|            image|https://i.pinimg....|     /data/education|     education|\n| 7922|a584581c-1b38-473...|45 Top Life Quote...|summcoco gives yo...|        306000|Sumcoco | Decor I...|Life Quotes Love,...|            image|https://i.pinimg....|        /data/quotes|        quotes|\n| 1643|41be1bcd-1ead-476...|White and Gold Ch...|Connecticut life ...|         84000|      Lauren McBride|Christmas Dining ...|            image|https://i.pinimg....|     /data/christmas|     christmas|\n| 5091|43459535-64e9-48a...|Buying Your First...|Buying your first...|           223|Edwin | Cash The ...|Paying Off Car Lo...|            image|https://i.pinimg....|       /data/finance|       finance|\n| 9979|2b2abc85-fc51-481...|Paris in the Summ...|Are you traveling...|          3000|     Petite in Paris|Torre Eiffel Pari...|            image|https://i.pinimg....|        /data/travel|        travel|\n| 3032|208b07bc-e042-4e8...|   Puffy Ghost Craft|This ghost craft ...|         56000|       Thriving Home|Halloween Arts An...|            video|https://i.pinimg....|/data/diy-and-crafts|diy-and-crafts|\n| 6809|f8ca698f-abfc-4b6...|It&#39;s Time to Ditc...|It&#39;s safe to assu...|        383000|        Suburban Men|Business Casual D...|            image|https://i.pinimg....|  /data/mens-fashion|  mens-fashion|\n| 3644|cde2b4e2-7711-4a8...|More Amazon Must ...|Amazon is a teach...|         41000|Teach Create Moti...|Classroom Hacks,5...|            image|https://i.pinimg....|     /data/education|     education|\n| 6575|15c45907-657e-439...|Affordable Farmho...|Believe it or not...|         31000| Maria Louise Design|Farmhouse Remodel...|            image|https://i.pinimg....|    /data/home-decor|    home-decor|\n| 6145|82e13a07-db99-43a...|HOLIDAY MANTLE DE...|Holiday mantle de...|         83000|     Stylin by Aylin|Winter Home Decor...|            image|https://i.pinimg....|    /data/home-decor|    home-decor|\n| 6145|82e13a07-db99-43a...|HOLIDAY MANTLE DE...|Holiday mantle de...|         83000|     Stylin by Aylin|Winter Home Decor...|            image|https://i.pinimg....|    /data/home-decor|    home-decor|\n|    4|55abcd28-bda1-445...|Mexican Artist Us...|Mexican artist En...|          null|         Bored Panda|Girl Drawing Sket...|            image|https://i.pinimg....|           /data/art|           art|\n| 4315|21b59ba9-829d-4c3...|Podcasts for Teac...|Podcasts for Teac...|         25000|        Math Giraffe|Middle School Cla...|            image|https://i.pinimg....|     /data/education|     education|\n| 5069|b75b6f87-deb3-444...|The Vault: Curate...|Sacramento Califo...|          null|     Style Me Pretty|60th Anniversary ...|            image|https://i.pinimg....|/data/event-planning|event-planning|\n+-----+--------------------+--------------------+--------------------+--------------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_df_pin = clean_pin_dataframe(df_pin)\n",
    "cleaned_df_pin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to clean dataframes\n",
    "I created a function to clean the \"df_geo\" DataFrame, it can encapsulate the cleaning steps into a single function. \n",
    "\n",
    "Also I created an error handling to the function, it can use a try-except block to catch any potential errors that may occur during the cleaning process. Here's the function with error handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db087075-eaf8-4e92-9044-9d1dc60def14",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d2c8ce4-d984-4cfe-8a5f-e3b9d4565f6d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### To clean the df_geo DataFrame you should perform the following transformations:\n",
    "\n",
    "- Create a new column coordinates that contains an array based on the latitude and longitude columns\n",
    "- Drop the latitude and longitude columns from the DataFrame\n",
    "- Convert the timestamp column from a string to a timestamp data type\n",
    "- Reorder the DataFrame columns to have the following column order:\n",
    "  - ind\n",
    "  - country\n",
    "  - coordinates\n",
    "  - timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "222eb65b-8a3f-423c-b826-00bd64d6b53a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array, col, to_timestamp\n",
    "\n",
    "def clean_geo_dataframe(df_geo):\n",
    "    \"\"\"\n",
    "    Clean the DataFrame that contains information about Pinterest geolocation data.\n",
    "\n",
    "    Parameters:\n",
    "    df_geo (DataFrame): DataFrame containing Pinterest geolocation data.\n",
    "\n",
    "    Returns:\n",
    "    df_geo_cleaned (DataFrame): Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a new column coordinates containing an array of latitude and longitude\n",
    "        df_geo_cleaned = df_geo.withColumn(\"coordinates\", array(col(\"latitude\"), col(\"longitude\")))\n",
    "\n",
    "        # Drop the latitude and longitude columns\n",
    "        df_geo_cleaned = df_geo_cleaned.drop(\"latitude\", \"longitude\")\n",
    "\n",
    "        # Convert the timestamp column to a timestamp data type\n",
    "        df_geo_cleaned = df_geo_cleaned.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))\n",
    "\n",
    "        # Reorder the DataFrame columns\n",
    "        df_geo_cleaned = df_geo_cleaned.select(\"ind\", \"country\", \"coordinates\", \"timestamp\")\n",
    "\n",
    "        return df_geo_cleaned\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data cleaning: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then call this function passing the \"df_geo\" DataFrame as an argument to clean it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01896373-6342-4e14-b418-4b340df1f4c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----+--------------------+--------------------+-------------------+\n",
       "  ind|             country|         coordinates|          timestamp|\n",
       "+-----+--------------------+--------------------+-------------------+\n",
       " 2418|Antarctica (the t...|[-88.4642, -171.061]|2022-05-27 11:30:59|\n",
       " 9270|Bouvet Island (Bo...|[-84.3984, -144.933]|2022-05-23 03:24:24|\n",
       "10794|Cocos (Keeling) I...|[-89.5236, -154.567]|2022-01-01 02:26:50|\n",
       " 5395|British Virgin Is...|[-6.93422, -24.9989]|2020-08-15 19:30:19|\n",
       " 2074|Central African R...|  [-52.3213, -50.11]|2019-11-03 05:41:59|\n",
       " 1170|Libyan Arab Jamah...|  [56.1198, 20.2963]|2019-08-07 22:17:07|\n",
       " 9550|British Virgin Is...|  [-84.918, 7.23235]|2022-03-23 00:25:45|\n",
       " 7922| Antigua and Barbuda|[-88.0974, -172.052]|2021-01-27 09:14:19|\n",
       " 9979|  Dominican Republic| [14.9967, -120.682]|2018-07-18 19:01:46|\n",
       " 6575|  Dominican Republic|  [81.7192, 61.5152]|2020-12-29 22:59:37|\n",
       " 3032|      American Samoa|[-66.7253, -122.489]|2018-04-14 09:28:18|\n",
       "  637|      American Samoa|[-41.2244, -158.022]|2018-06-06 01:25:58|\n",
       "10321|        Burkina Faso|[-89.1005, -151.255]|2022-10-09 08:06:50|\n",
       " 2923|       Cote d&#39;Ivoire|[-84.6302, -164.507]|2019-09-08 22:53:09|\n",
       " 8304|       French Guiana| [-28.8852, -164.87]|2019-09-13 04:50:29|\n",
       " 4315|       Cote d&#39;Ivoire| [-45.8508, 66.1003]|2019-12-15 03:51:28|\n",
       " 4249|         Afghanistan|[-88.5478, -174.971]|2021-09-01 11:10:02|\n",
       " 6809|          Bangladesh|[-89.4254, -161.818]|2020-04-17 13:20:43|\n",
       " 5069|          Azerbaijan|[-63.0063, -157.474]|2021-03-20 09:32:44|\n",
       " 6145|          Mozambique|[-65.9079, -143.845]|2019-12-05 02:09:44|\n",
       "+-----+--------------------+--------------------+-------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-----+--------------------+--------------------+-------------------+\n|  ind|             country|         coordinates|          timestamp|\n+-----+--------------------+--------------------+-------------------+\n| 2418|Antarctica (the t...|[-88.4642, -171.061]|2022-05-27 11:30:59|\n| 9270|Bouvet Island (Bo...|[-84.3984, -144.933]|2022-05-23 03:24:24|\n|10794|Cocos (Keeling) I...|[-89.5236, -154.567]|2022-01-01 02:26:50|\n| 5395|British Virgin Is...|[-6.93422, -24.9989]|2020-08-15 19:30:19|\n| 2074|Central African R...|  [-52.3213, -50.11]|2019-11-03 05:41:59|\n| 1170|Libyan Arab Jamah...|  [56.1198, 20.2963]|2019-08-07 22:17:07|\n| 9550|British Virgin Is...|  [-84.918, 7.23235]|2022-03-23 00:25:45|\n| 7922| Antigua and Barbuda|[-88.0974, -172.052]|2021-01-27 09:14:19|\n| 9979|  Dominican Republic| [14.9967, -120.682]|2018-07-18 19:01:46|\n| 6575|  Dominican Republic|  [81.7192, 61.5152]|2020-12-29 22:59:37|\n| 3032|      American Samoa|[-66.7253, -122.489]|2018-04-14 09:28:18|\n|  637|      American Samoa|[-41.2244, -158.022]|2018-06-06 01:25:58|\n|10321|        Burkina Faso|[-89.1005, -151.255]|2022-10-09 08:06:50|\n| 2923|       Cote d&#39;Ivoire|[-84.6302, -164.507]|2019-09-08 22:53:09|\n| 8304|       French Guiana| [-28.8852, -164.87]|2019-09-13 04:50:29|\n| 4315|       Cote d&#39;Ivoire| [-45.8508, 66.1003]|2019-12-15 03:51:28|\n| 4249|         Afghanistan|[-88.5478, -174.971]|2021-09-01 11:10:02|\n| 6809|          Bangladesh|[-89.4254, -161.818]|2020-04-17 13:20:43|\n| 5069|          Azerbaijan|[-63.0063, -157.474]|2021-03-20 09:32:44|\n| 6145|          Mozambique|[-65.9079, -143.845]|2019-12-05 02:09:44|\n+-----+--------------------+--------------------+-------------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_df_geo = clean_pin_dataframe(df_geo)\n",
    "cleaned_df_geo.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f19212f-db12-4782-bd0d-4f5ea685503b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 3:\n",
    "1. Create a new column user_name by concatenating first_name and last_name\n",
    "2. Drop the first_name and last_name columns\n",
    "3. Convert the date_joined column to a timestamp data type\n",
    "4. Reorder the DataFrame columns\n",
    "   - \"ind\", \"user_name\", \"age\", \"date_joined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b09e380-bae6-4840-a206-d51a8b6f18d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, col, to_timestamp\n",
    "\n",
    "def clean_user_dataframe(df_user):\n",
    "    \"\"\"\n",
    "    Clean the DataFrame that contains information about Pinterest user data.\n",
    "\n",
    "    Parameters:\n",
    "    df_user (DataFrame): DataFrame containing Pinterest user data.\n",
    "\n",
    "    Returns:\n",
    "    df_user_cleaned (DataFrame): Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Create a new column user_name by concatenating first_name and last_name\n",
    "        df_user_cleaned = df_user.withColumn(\"user_name\", concat(col(\"first_name\"), col(\"last_name\")))\n",
    "\n",
    "        # 2. Drop the first_name and last_name columns\n",
    "        df_user_cleaned = df_user_cleaned.drop(\"first_name\", \"last_name\")\n",
    "\n",
    "        # 3. Convert the date_joined column to a timestamp data type\n",
    "        df_user_cleaned = df_user_cleaned.withColumn(\"date_joined\", to_timestamp(\"date_joined\"))\n",
    "\n",
    "        # 4. Reorder the DataFrame columns\n",
    "        df_user_cleaned = df_user_cleaned.select(\"ind\", \"user_name\", \"age\", \"date_joined\")\n",
    "\n",
    "        return df_user_cleaned\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data cleaning: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then call this function passing the \"df_user\" DataFrame as an argument to clean it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75caf69a-3703-4c57-b4e9-a7f82e58d849",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----+------------------+---+-------------------+\n",
       "  ind|         user_name|age|        date_joined|\n",
       "+-----+------------------+---+-------------------+\n",
       " 4249|AlexandriaAlvarado| 20|2015-10-23 04:13:23|\n",
       " 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|\n",
       " 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|\n",
       " 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|\n",
       "10137|    DanielMatthews| 34|2016-01-23 03:59:37|\n",
       " 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|\n",
       " 8887|   AustinRodriguez| 24|2016-03-31 20:56:39|\n",
       " 4315|    MichellePrince| 36|2015-12-20 16:38:13|\n",
       "10625|     ChristianLang| 32|2017-10-10 20:09:33|\n",
       " 4315|    MichellePrince| 36|2015-12-20 16:38:13|\n",
       " 1514|    MichaelPerkins| 40|2017-06-28 16:17:39|\n",
       " 4315|    MichellePrince| 36|2015-12-20 16:38:13|\n",
       "10625|     ChristianLang| 32|2017-10-10 20:09:33|\n",
       "10625|     ChristianLang| 32|2017-10-10 20:09:33|\n",
       " 9672|    JenniferHudson| 22|2016-02-11 20:46:04|\n",
       " 1313|     BrittanyJones| 32|2016-04-02 03:51:23|\n",
       " 1313|     BrittanyJones| 32|2016-04-02 03:51:23|\n",
       "10794|      ThomasTurner| 34|2016-12-22 00:02:02|\n",
       " 1313|     BrittanyJones| 32|2016-04-02 03:51:23|\n",
       "10794|      ThomasTurner| 34|2016-12-22 00:02:02|\n",
       "+-----+------------------+---+-------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-----+------------------+---+-------------------+\n|  ind|         user_name|age|        date_joined|\n+-----+------------------+---+-------------------+\n| 4249|AlexandriaAlvarado| 20|2015-10-23 04:13:23|\n| 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|\n| 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|\n| 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|\n|10137|    DanielMatthews| 34|2016-01-23 03:59:37|\n| 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|\n| 8887|   AustinRodriguez| 24|2016-03-31 20:56:39|\n| 4315|    MichellePrince| 36|2015-12-20 16:38:13|\n|10625|     ChristianLang| 32|2017-10-10 20:09:33|\n| 4315|    MichellePrince| 36|2015-12-20 16:38:13|\n| 1514|    MichaelPerkins| 40|2017-06-28 16:17:39|\n| 4315|    MichellePrince| 36|2015-12-20 16:38:13|\n|10625|     ChristianLang| 32|2017-10-10 20:09:33|\n|10625|     ChristianLang| 32|2017-10-10 20:09:33|\n| 9672|    JenniferHudson| 22|2016-02-11 20:46:04|\n| 1313|     BrittanyJones| 32|2016-04-02 03:51:23|\n| 1313|     BrittanyJones| 32|2016-04-02 03:51:23|\n|10794|      ThomasTurner| 34|2016-12-22 00:02:02|\n| 1313|     BrittanyJones| 32|2016-04-02 03:51:23|\n|10794|      ThomasTurner| 34|2016-12-22 00:02:02|\n+-----+------------------+---+-------------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_df_user = clean_pin_dataframe(df_user)\n",
    "cleaned_df_user.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33ce4ace-b6a7-4ef5-826b-ecefcbd6e83b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 4: Find the most popular category by country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68a2ea3f-c7c9-4498-b897-54c952b3312c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Find the most popular Pinterest category people post to based on their country.\n",
    "Your query should return a DataFrame that contains the following columns:\n",
    "- country\n",
    "- category\n",
    "- category_count, a new column containing the desired query output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31640dc5-7a18-4c0b-b2d3-2bc3c21a38ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "894d591c-22f2-43f6-b620-94f092534e7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------------+--------------+--------------+\n",
       "             country|      category|category_count|\n",
       "+--------------------+--------------+--------------+\n",
       "         Afghanistan|     education|             1|\n",
       "             Albania|  mens-fashion|             4|\n",
       "             Algeria|        quotes|             1|\n",
       "      American Samoa|diy-and-crafts|             1|\n",
       "              Angola|diy-and-crafts|             4|\n",
       "            Anguilla|    home-decor|             1|\n",
       "Antarctica (the t...|     christmas|             1|\n",
       " Antigua and Barbuda|        quotes|             1|\n",
       "             Armenia|diy-and-crafts|             5|\n",
       "               Aruba|        travel|             1|\n",
       "           Australia|  mens-fashion|             1|\n",
       "             Austria|event-planning|             1|\n",
       "          Azerbaijan|event-planning|             1|\n",
       "             Bahamas|           art|             1|\n",
       "          Bangladesh|  mens-fashion|             1|\n",
       "            Barbados|        travel|             4|\n",
       "            Botswana|       tattoos|             1|\n",
       "Bouvet Island (Bo...|       tattoos|             1|\n",
       "British Virgin Is...|        travel|             1|\n",
       "            Bulgaria|       finance|             1|\n",
       "+--------------------+--------------+--------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------------------+--------------+--------------+\n|             country|      category|category_count|\n+--------------------+--------------+--------------+\n|         Afghanistan|     education|             1|\n|             Albania|  mens-fashion|             4|\n|             Algeria|        quotes|             1|\n|      American Samoa|diy-and-crafts|             1|\n|              Angola|diy-and-crafts|             4|\n|            Anguilla|    home-decor|             1|\n|Antarctica (the t...|     christmas|             1|\n| Antigua and Barbuda|        quotes|             1|\n|             Armenia|diy-and-crafts|             5|\n|               Aruba|        travel|             1|\n|           Australia|  mens-fashion|             1|\n|             Austria|event-planning|             1|\n|          Azerbaijan|event-planning|             1|\n|             Bahamas|           art|             1|\n|          Bangladesh|  mens-fashion|             1|\n|            Barbados|        travel|             4|\n|            Botswana|       tattoos|             1|\n|Bouvet Island (Bo...|       tattoos|             1|\n|British Virgin Is...|        travel|             1|\n|            Bulgaria|       finance|             1|\n+--------------------+--------------+--------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Alias the DataFrames before joining them\n",
    "df_pin_alias = df_pin.withColumnRenamed(\"country\", \"pin_country\").alias(\"pin\")\n",
    "df_geo_alias = df_geo.withColumnRenamed(\"country\", \"geo_country\").alias(\"geo\")\n",
    "\n",
    "# Join df_pin with df_geo on the index column\n",
    "df_combined = df_pin_alias.join(df_geo_alias, df_pin_alias.ind == df_geo_alias.ind)\n",
    "\n",
    "# Group by country and category, then count the occurrences of each category for each country\n",
    "df_category_count = df_combined.groupBy(df_geo_alias[\"geo_country\"], df_pin_alias[\"category\"]).count()\n",
    "\n",
    "# Create a window partitioned by country, ordered by the count descending\n",
    "windowSpec = Window.partitionBy(\"geo_country\").orderBy(col(\"count\").desc())\n",
    "\n",
    "# Use row_number to assign a rank to each row within each country partition\n",
    "df_ranked_categories = df_category_count.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to get only the top category (rank = 1) for each country\n",
    "df_top_category_per_country = df_ranked_categories.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Select the desired columns\n",
    "# This is the erroneours line.\n",
    "####### df_most_popular = df_most_popular.select(\"geo_country\", \"category\", \"count\")\n",
    "\n",
    "# Filter to get only the top category (rank = 1) for each country\n",
    "df_most_popular = df_ranked_categories.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Rename the columns\n",
    "df_most_popular = df_most_popular.withColumnRenamed(\"geo_country\", \"country\")\n",
    "df_most_popular = df_most_popular.withColumnRenamed(\"count\", \"category_count\")\n",
    "\n",
    "# Display the result\n",
    "df_most_popular.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d041eb0a-eba5-47d1-9a0c-7aa0c8131617",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------------+--------------+--------------+\n",
       "             country|      category|category_count|\n",
       "+--------------------+--------------+--------------+\n",
       "         Afghanistan|     education|             1|\n",
       "             Albania|  mens-fashion|             4|\n",
       "             Algeria|        quotes|             1|\n",
       "      American Samoa|           art|             1|\n",
       "              Angola|diy-and-crafts|             4|\n",
       "            Anguilla|    home-decor|             1|\n",
       "Antarctica (the t...|     christmas|             1|\n",
       " Antigua and Barbuda|        quotes|             1|\n",
       "             Armenia|diy-and-crafts|             5|\n",
       "               Aruba|        travel|             1|\n",
       "           Australia|  mens-fashion|             1|\n",
       "             Austria|        travel|             1|\n",
       "          Azerbaijan|event-planning|             1|\n",
       "             Bahamas|           art|             1|\n",
       "          Bangladesh|           art|             1|\n",
       "            Barbados|        travel|             4|\n",
       "            Botswana|       tattoos|             1|\n",
       "Bouvet Island (Bo...|       tattoos|             1|\n",
       "British Virgin Is...|        travel|             1|\n",
       "            Bulgaria|       finance|             1|\n",
       "+--------------------+--------------+--------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------------------+--------------+--------------+\n|             country|      category|category_count|\n+--------------------+--------------+--------------+\n|         Afghanistan|     education|             1|\n|             Albania|  mens-fashion|             4|\n|             Algeria|        quotes|             1|\n|      American Samoa|           art|             1|\n|              Angola|diy-and-crafts|             4|\n|            Anguilla|    home-decor|             1|\n|Antarctica (the t...|     christmas|             1|\n| Antigua and Barbuda|        quotes|             1|\n|             Armenia|diy-and-crafts|             5|\n|               Aruba|        travel|             1|\n|           Australia|  mens-fashion|             1|\n|             Austria|        travel|             1|\n|          Azerbaijan|event-planning|             1|\n|             Bahamas|           art|             1|\n|          Bangladesh|           art|             1|\n|            Barbados|        travel|             4|\n|            Botswana|       tattoos|             1|\n|Bouvet Island (Bo...|       tattoos|             1|\n|British Virgin Is...|        travel|             1|\n|            Bulgaria|       finance|             1|\n+--------------------+--------------+--------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Alias the DataFrames before joining them\n",
    "df_pin_alias = df_pin.withColumnRenamed(\"country\", \"pin_country\").alias(\"pin\")\n",
    "df_geo_alias = df_geo.withColumnRenamed(\"country\", \"geo_country\").alias(\"geo\")\n",
    "\n",
    "# Join df_pin with df_geo on the index column\n",
    "df_combined = df_pin_alias.join(df_geo_alias, df_pin_alias.ind == df_geo_alias.ind)\n",
    "\n",
    "# Group by country and category, then count the occurrences of each category for each country\n",
    "df_category_count = df_combined.groupBy(df_geo_alias[\"geo_country\"], df_pin_alias[\"category\"]).count()\n",
    "\n",
    "# Create a window partitioned by country, ordered by the count descending\n",
    "windowSpec = Window.partitionBy(\"geo_country\").orderBy(col(\"count\").desc())\n",
    "\n",
    "# Use row_number to assign a rank to each row within each country partition\n",
    "df_ranked_categories = df_category_count.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to get only the top category (rank = 1) for each country\n",
    "df_top_category_per_country = df_ranked_categories.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Select the desired columns\n",
    "# This is the erroneours line.\n",
    "####### df_most_popular = df_most_popular.select(\"geo_country\", \"category\", \"count\")\n",
    "\n",
    "# Filter to get only the top category (rank = 1) for each country\n",
    "df_most_popular = df_ranked_categories.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Rename the columns\n",
    "df_most_popular = df_most_popular.withColumnRenamed(\"geo_country\", \"country\")\n",
    "df_most_popular = df_most_popular.withColumnRenamed(\"count\", \"category_count\")\n",
    "\n",
    "# Display the result\n",
    "df_most_popular.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4175043e-d394-48ee-b8cd-79c4b96adb0f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaa9e327-2cb5-46bb-a420-0188f3e43fbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">DataFrame[ind: bigint, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string, ind: bigint, geo_country: string, coordinates: array&lt;double&gt;, timestamp: timestamp]\n",
       "DataFrame[geo_country: string, category: string, count: bigint]\n",
       "DataFrame[geo_country: string, max(count): bigint]\n",
       "+--------------------+----------+\n",
       "         geo_country|max(count)|\n",
       "+--------------------+----------+\n",
       "            Anguilla|         1|\n",
       "                Fiji|         1|\n",
       "            Cambodia|         1|\n",
       "         Afghanistan|         1|\n",
       "            Maldives|         1|\n",
       "               Sudan|         1|\n",
       "British Virgin Is...|         1|\n",
       "             Algeria|         1|\n",
       "              Angola|         4|\n",
       "             Albania|         4|\n",
       "               India|         1|\n",
       "             Bahamas|         1|\n",
       "      American Samoa|         1|\n",
       "             Burundi|         1|\n",
       "Central African R...|         1|\n",
       "          Bangladesh|         1|\n",
       "            Barbados|         4|\n",
       "               Congo|         1|\n",
       "Cocos (Keeling) I...|         1|\n",
       "       Cote d&#39;Ivoire|         1|\n",
       "+--------------------+----------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">DataFrame[ind: bigint, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string, ind: bigint, geo_country: string, coordinates: array&lt;double&gt;, timestamp: timestamp]\nDataFrame[geo_country: string, category: string, count: bigint]\nDataFrame[geo_country: string, max(count): bigint]\n+--------------------+----------+\n|         geo_country|max(count)|\n+--------------------+----------+\n|            Anguilla|         1|\n|                Fiji|         1|\n|            Cambodia|         1|\n|         Afghanistan|         1|\n|            Maldives|         1|\n|               Sudan|         1|\n|British Virgin Is...|         1|\n|             Algeria|         1|\n|              Angola|         4|\n|             Albania|         4|\n|               India|         1|\n|             Bahamas|         1|\n|      American Samoa|         1|\n|             Burundi|         1|\n|Central African R...|         1|\n|          Bangladesh|         1|\n|            Barbados|         4|\n|               Congo|         1|\n|Cocos (Keeling) I...|         1|\n|       Cote d&#39;Ivoire|         1|\n+--------------------+----------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Alias the DataFrames before joining them\n",
    "df_pin_alias = df_pin.withColumnRenamed(\"country\", \"pin_country\").alias(\"pin\")\n",
    "df_geo_alias = df_geo.withColumnRenamed(\"country\", \"geo_country\").alias(\"geo\")\n",
    "\n",
    "# Join df_pin with df_geo on the index column\n",
    "df_combined = df_pin_alias.join(df_geo_alias, df_pin_alias.ind == df_geo_alias.ind)\n",
    "print(df_combined)\n",
    "# Group by country and category, then count the occurrences of each category for each country\n",
    "df_category_count = df_combined.groupBy(\"geo_country\", \"pin.category\").count()\n",
    "print(df_category_count)\n",
    "# Find the maximum count for each country\n",
    "max_counts = df_category_count.groupBy(\"geo_country\").max(\"count\")\n",
    "print(max_counts)\n",
    "\n",
    "max_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5b78584-61ae-48c9-9492-07170473d8b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">DataFrame[ind: bigint, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string, ind: bigint, geo_country: string, coordinates: array&lt;double&gt;, timestamp: timestamp]\n",
       "DataFrame[geo_country: string, category: string, count: bigint]\n",
       "DataFrame[geo_country: string, max(count): bigint]\n",
       "+--------------------+----------+\n",
       "         geo_country|max(count)|\n",
       "+--------------------+----------+\n",
       "            Anguilla|         1|\n",
       "                Fiji|         1|\n",
       "         Afghanistan|         1|\n",
       "            Cambodia|         1|\n",
       "            Maldives|         1|\n",
       "               Sudan|         1|\n",
       "British Virgin Is...|         1|\n",
       "             Algeria|         1|\n",
       "              Angola|         4|\n",
       "             Albania|         4|\n",
       "               India|         1|\n",
       "             Bahamas|         1|\n",
       "      American Samoa|         1|\n",
       "             Burundi|         1|\n",
       "Central African R...|         1|\n",
       "          Bangladesh|         1|\n",
       "            Barbados|         4|\n",
       "               Congo|         1|\n",
       "Cocos (Keeling) I...|         1|\n",
       "       Cote d&#39;Ivoire|         1|\n",
       "+--------------------+----------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">DataFrame[ind: bigint, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string, ind: bigint, geo_country: string, coordinates: array&lt;double&gt;, timestamp: timestamp]\nDataFrame[geo_country: string, category: string, count: bigint]\nDataFrame[geo_country: string, max(count): bigint]\n+--------------------+----------+\n|         geo_country|max(count)|\n+--------------------+----------+\n|            Anguilla|         1|\n|                Fiji|         1|\n|         Afghanistan|         1|\n|            Cambodia|         1|\n|            Maldives|         1|\n|               Sudan|         1|\n|British Virgin Is...|         1|\n|             Algeria|         1|\n|              Angola|         4|\n|             Albania|         4|\n|               India|         1|\n|             Bahamas|         1|\n|      American Samoa|         1|\n|             Burundi|         1|\n|Central African R...|         1|\n|          Bangladesh|         1|\n|            Barbados|         4|\n|               Congo|         1|\n|Cocos (Keeling) I...|         1|\n|       Cote d&#39;Ivoire|         1|\n+--------------------+----------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Alias the DataFrames before joining them\n",
    "df_pin_alias = df_pin.withColumnRenamed(\"country\", \"pin_country\").alias(\"pin\")\n",
    "df_geo_alias = df_geo.withColumnRenamed(\"country\", \"geo_country\").alias(\"geo\")\n",
    "\n",
    "# Join df_pin with df_geo on the index column\n",
    "df_combined = df_pin_alias.join(df_geo_alias, df_pin_alias.ind == df_geo_alias.ind)\n",
    "print(df_combined)\n",
    "# Group by country and category, then count the occurrences of each category for each country\n",
    "df_category_count = df_combined.groupBy(\"geo_country\", \"pin.category\").count()\n",
    "print(df_category_count)\n",
    "# Find the maximum count for each country\n",
    "max_counts = df_category_count.groupBy(\"geo_country\").max(\"count\")\n",
    "print(max_counts)\n",
    "\n",
    "max_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c8c0821-e7e6-442f-bc17-1d86a84d2e7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">DataFrame[ind: bigint, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string]\n",
       "DataFrame[ind: bigint, geo_country: string, coordinates: array&lt;double&gt;, timestamp: timestamp]\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">DataFrame[ind: bigint, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string]\nDataFrame[ind: bigint, geo_country: string, coordinates: array&lt;double&gt;, timestamp: timestamp]\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Alias the DataFrames before joining them\n",
    "df_pin_alias = df_pin.withColumnRenamed(\"country\", \"pin_country\").alias(\"pin\")\n",
    "df_geo_alias = df_geo.withColumnRenamed(\"country\", \"geo_country\").alias(\"geo\")\n",
    "print(df_pin_alias)\n",
    "print(df_geo_alias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a11442a0-68f3-4cbb-8378-28a5009e4302",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 5: Find which was the most popular category each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5e316eb-d142-4bed-91ad-24525abcf41e",
     "showTitle": true,
     "title": "# Task 5: Find which was the most popular category each year"
    }
   },
   "source": [
    "Task 5: Find which was the most popular category each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3bbc37c-1511-4f7e-8692-940253563a73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+--------------+--------------+\n",
       "year|      category|category_count|\n",
       "+----+--------------+--------------+\n",
       "2018|      vehicles|             4|\n",
       "2019|diy-and-crafts|             5|\n",
       "2020|  mens-fashion|             6|\n",
       "2021|        quotes|             2|\n",
       "2022|     christmas|             2|\n",
       "+----+--------------+--------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----+--------------+--------------+\n|year|      category|category_count|\n+----+--------------+--------------+\n|2018|      vehicles|             4|\n|2019|diy-and-crafts|             5|\n|2020|  mens-fashion|             6|\n|2021|        quotes|             2|\n|2022|     christmas|             2|\n+----+--------------+--------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, year\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Combine the data from df_pin and df_geo\n",
    "df_combined = df_pin.join(df_geo, df_pin.ind == df_geo.ind)\n",
    "\n",
    "# Extract the year from the timestamp column\n",
    "df_combined = df_combined.withColumn(\"year\", year(\"timestamp\"))\n",
    "\n",
    "# Group by year and category, then count the occurrences of each category for each year\n",
    "df_category_count = df_combined.groupBy(\"year\", \"category\").count()\n",
    "\n",
    "# Create a window partitioned by year, ordered by the count descending\n",
    "windowSpec = Window.partitionBy(\"year\").orderBy(col(\"count\").desc())\n",
    "\n",
    "# Use row_number to assign a rank to each row within each year partition\n",
    "df_ranked_categories = df_category_count.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to get only the top category (rank = 1) for each year\n",
    "df_top_category_per_year = df_ranked_categories.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Rename the columns\n",
    "#df_top_category_per_year = df_top_category_per_year.withColumnRenamed(\"category\", \"most_popular_category\")\n",
    "df_top_category_per_year = df_top_category_per_year.withColumnRenamed(\"count\", \"category_count\")\n",
    "\n",
    "# Display the result\n",
    "df_top_category_per_year.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a49308e-929a-4d73-b4a5-62da82c16bc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+--------------+--------------+\n",
       "post_year|      category|category_count|\n",
       "+---------+--------------+--------------+\n",
       "     2018|      vehicles|             4|\n",
       "     2019|diy-and-crafts|             5|\n",
       "     2020|  mens-fashion|             6|\n",
       "     2021|       tattoos|             2|\n",
       "     2022|     christmas|             2|\n",
       "+---------+--------------+--------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---------+--------------+--------------+\n|post_year|      category|category_count|\n+---------+--------------+--------------+\n|     2018|      vehicles|             4|\n|     2019|diy-and-crafts|             5|\n|     2020|  mens-fashion|             6|\n|     2021|       tattoos|             2|\n|     2022|     christmas|             2|\n+---------+--------------+--------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, year\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Combine the data from df_pin and df_geo\n",
    "df_combined = df_pin.join(df_geo, df_pin.ind == df_geo.ind)\n",
    "\n",
    "# Extract the year from the timestamp column and rename it to post_year\n",
    "df_combined = df_combined.withColumn(\"post_year\", year(\"timestamp\")).drop(\"year\")\n",
    "\n",
    "# Group by post_year and category, then count the occurrences of each category for each post_year\n",
    "df_category_count = df_combined.groupBy(\"post_year\", \"category\").count()\n",
    "\n",
    "# Create a window partitioned by post_year, ordered by the count descending\n",
    "windowSpec = Window.partitionBy(\"post_year\").orderBy(col(\"count\").desc())\n",
    "\n",
    "# Use row_number to assign a rank to each row within each post_year partition\n",
    "df_ranked_categories = df_category_count.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to get only the top category (rank = 1) for each post_year\n",
    "df_top_category_per_year = df_ranked_categories.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Rename the columns\n",
    "df_top_category_per_year = df_top_category_per_year.withColumnRenamed(\"count\", \"category_count\")\n",
    "\n",
    "# Display the result\n",
    "df_top_category_per_year.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32edd894-b69d-4837-ad9f-a173e037c341",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 6: Find the user with most followers in each country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4d5762a-5194-4cc7-82c6-dc7947c0eb74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 1: For each country find the user with the most followers.\n",
    "Your query should return a DataFrame that contains the following columns:\n",
    "\n",
    "- country\n",
    "- poster_name\n",
    "- follower_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7972df0c-eaef-4081-b31f-ea3f69debefb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------------+--------------------+--------------+\n",
       "             country|         poster_name|follower_count|\n",
       "+--------------------+--------------------+--------------+\n",
       "         Afghanistan|             Walmart|          null|\n",
       "             Albania|         Bored Panda|          null|\n",
       "             Algeria|           YourTango|        942000|\n",
       "      American Samoa|       Thriving Home|         56000|\n",
       "              Angola|     CraftGossip.com|        502000|\n",
       "            Anguilla|Kristen | Lifesty...|         92000|\n",
       "Antarctica (the t...|            HikenDip|        500000|\n",
       " Antigua and Barbuda|Sumcoco | Decor I...|        306000|\n",
       "             Armenia|Michelle {CraftyM...|        892000|\n",
       "               Aruba|     TheTrendSpotter|        211000|\n",
       "           Australia|   Cultura Colectiva|          null|\n",
       "             Austria|Wanderlust Chloe ...|         10000|\n",
       "          Azerbaijan|     Style Me Pretty|          null|\n",
       "             Bahamas|The Kitchen Table...|        221000|\n",
       "          Bangladesh|        Suburban Men|        383000|\n",
       "            Barbados|              Nicki |         28000|\n",
       "            Botswana|          RapidLeaks|          4000|\n",
       "Bouvet Island (Bo...|            POPSUGAR|          null|\n",
       "British Virgin Is...|Visit USA Parks |...|          4000|\n",
       "            Bulgaria|Living Low Key | ...|         26000|\n",
       "+--------------------+--------------------+--------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------------------+--------------------+--------------+\n|             country|         poster_name|follower_count|\n+--------------------+--------------------+--------------+\n|         Afghanistan|             Walmart|          null|\n|             Albania|         Bored Panda|          null|\n|             Algeria|           YourTango|        942000|\n|      American Samoa|       Thriving Home|         56000|\n|              Angola|     CraftGossip.com|        502000|\n|            Anguilla|Kristen | Lifesty...|         92000|\n|Antarctica (the t...|            HikenDip|        500000|\n| Antigua and Barbuda|Sumcoco | Decor I...|        306000|\n|             Armenia|Michelle {CraftyM...|        892000|\n|               Aruba|     TheTrendSpotter|        211000|\n|           Australia|   Cultura Colectiva|          null|\n|             Austria|Wanderlust Chloe ...|         10000|\n|          Azerbaijan|     Style Me Pretty|          null|\n|             Bahamas|The Kitchen Table...|        221000|\n|          Bangladesh|        Suburban Men|        383000|\n|            Barbados|              Nicki |         28000|\n|            Botswana|          RapidLeaks|          4000|\n|Bouvet Island (Bo...|            POPSUGAR|          null|\n|British Virgin Is...|Visit USA Parks |...|          4000|\n|            Bulgaria|Living Low Key | ...|         26000|\n+--------------------+--------------------+--------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Alias the DataFrames before joining them\n",
    "df_pin_alias = df_pin.withColumnRenamed(\"country\", \"pin_country\").alias(\"pin\")\n",
    "df_geo_alias = df_geo.withColumnRenamed(\"country\", \"geo_country\").alias(\"geo\")\n",
    "\n",
    "# Join df_pin with df_geo on the index column\n",
    "df_combined = df_pin_alias.join(df_geo_alias, df_pin_alias.ind == df_geo_alias.ind)\n",
    "\n",
    "# Group by country and user (poster_name), then find the maximum follower count for each group\n",
    "df_max_followers_per_user = df_combined.groupBy(\"geo_country\", \"poster_name\").agg(max(\"follower_count\").alias(\"follower_count\"))\n",
    "\n",
    "# Create a window partitioned by country, ordered by the follower_count descending\n",
    "windowSpec = Window.partitionBy(\"geo_country\").orderBy(col(\"follower_count\").desc())\n",
    "\n",
    "# Use row_number to assign a rank to each row within each country partition\n",
    "df_ranked_users = df_max_followers_per_user.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to keep only the top user (rank = 1) for each country\n",
    "df_top_users_per_country = df_ranked_users.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Rename the columns\n",
    "df_top_users_per_country = df_top_users_per_country.withColumnRenamed(\"geo_country\", \"country\")\n",
    "\n",
    "# Select the desired columns\n",
    "df_top_users_per_country = df_top_users_per_country.select(\"country\", \"poster_name\", \"follower_count\")\n",
    "\n",
    "# Display the result\n",
    "df_top_users_per_country.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edebd814-54c7-4090-9fdb-bba7ec28f8b1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 2: Based on the above query, find the country with the user with most followers.\n",
    "Your query should return a DataFrame that contains the following columns:\n",
    "- country\n",
    "- follower_count\n",
    "\n",
    "This DataFrame should have only one entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c47d754-ef31-4a5b-a2a1-2a52db534106",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------+--------------+\n",
       "country|follower_count|\n",
       "+-------+--------------+\n",
       "Algeria|        942000|\n",
       "+-------+--------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------+--------------+\n|country|follower_count|\n+-------+--------------+\n|Algeria|        942000|\n+-------+--------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, max\n",
    "\n",
    "# Group by country and find the maximum follower count across all users in each country\n",
    "df_max_followers_per_country = df_top_users_per_country.groupBy(\"country\").agg(max(\"follower_count\").alias(\"follower_count\"))\n",
    "\n",
    "# Create a window partitioned by country, ordered by the follower_count descending\n",
    "windowSpec = Window.orderBy(col(\"follower_count\").desc())\n",
    "\n",
    "# Use row_number to assign a rank to each row\n",
    "df_ranked_countries = df_max_followers_per_country.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to keep only the top country (rank = 1)\n",
    "df_country_with_most_followers = df_ranked_countries.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Display the result\n",
    "df_country_with_most_followers.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7654b83b-3fed-41da-9e62-7a7c3e8c9c5b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 7: Find the most popular category for different age groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b24f2850-754f-431e-9dec-cffd1d91357d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "What is the most popular category people post to based on the following age groups:\n",
    "- 18-24\n",
    "- 25-35\n",
    "- 36-50\n",
    "- +50\n",
    "\n",
    "Your query should return a DataFrame that contains the following columns:\n",
    "- age_group, a new column based on the original age column\n",
    "- category\n",
    "- category_count, a new column containing the desired query output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a6eea0-5c04-4148-84bc-4658420a6525",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+--------------+--------------+\n",
       "age_group|      category|category_count|\n",
       "+---------+--------------+--------------+\n",
       "    18-24|  mens-fashion|            17|\n",
       "    25-35|diy-and-crafts|            12|\n",
       "    36-50|       finance|             5|\n",
       "      50+|        beauty|             1|\n",
       "+---------+--------------+--------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---------+--------------+--------------+\n|age_group|      category|category_count|\n+---------+--------------+--------------+\n|    18-24|  mens-fashion|            17|\n|    25-35|diy-and-crafts|            12|\n|    36-50|       finance|             5|\n|      50+|        beauty|             1|\n+---------+--------------+--------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Define age groups based on the original age column\n",
    "df_user_age_grouped = df_user.withColumn(\"age_group\",\n",
    "                                         when(col(\"age\").between(18, 24), \"18-24\")\n",
    "                                         .when(col(\"age\").between(25, 35), \"25-35\")\n",
    "                                         .when(col(\"age\").between(36, 50), \"36-50\")\n",
    "                                         .otherwise(\"50+\"))\n",
    "\n",
    "# Join the combined DataFrame with df_pin on the index column\n",
    "df_combined = df_pin.join(df_user_age_grouped, df_pin.ind == df_user_age_grouped.ind)\n",
    "\n",
    "# Group by age group and category, then count the occurrences of each category for each age group\n",
    "df_category_count = df_combined.groupBy(\"age_group\", \"category\").count()\n",
    "\n",
    "# Create a window partitioned by age group, ordered by the count descending\n",
    "windowSpec = Window.partitionBy(\"age_group\").orderBy(col(\"count\").desc())\n",
    "\n",
    "# Use row_number to assign a rank to each row within each age group partition\n",
    "df_ranked_categories = df_category_count.withColumn(\"rank\", row_number().over(windowSpec))\n",
    "\n",
    "# Filter to get only the top category (rank = 1) for each age group\n",
    "df_most_popular_per_age_group = df_ranked_categories.filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Rename the columns\n",
    "df_most_popular_per_age_group = df_most_popular_per_age_group.withColumnRenamed(\"count\", \"category_count\")\n",
    "\n",
    "# Display the result\n",
    "df_most_popular_per_age_group.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9ce8d96-81cd-475b-a8a3-754e65e07c87",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 8: Find the median follower count for different age groups\n",
    "\n",
    "What is the median follower count for users in the following age groups:\n",
    "\n",
    "- 18-24\n",
    "- 25-35\n",
    "- 36-50\n",
    "- +50\n",
    "\n",
    "Your query should return a DataFrame that contains the following columns:\n",
    "\n",
    "- age_group, a new column based on the original age column\n",
    "- median_follower_count, a new column containing the desired query output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bddb0fe-8185-4b61-9d45-9d54cae279db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+---------------------+\n",
       "age_group|median_follower_count|\n",
       "+---------+---------------------+\n",
       "    18-24|               211000|\n",
       "    25-35|                43000|\n",
       "    36-50|                 6000|\n",
       "      50+|                  908|\n",
       "+---------+---------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---------+---------------------+\n|age_group|median_follower_count|\n+---------+---------------------+\n|    18-24|               211000|\n|    25-35|                43000|\n|    36-50|                 6000|\n|      50+|                  908|\n+---------+---------------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Define age groups based on the original age column\n",
    "df_user_age_grouped = df_user.withColumn(\"age_group\",\n",
    "                                         when(col(\"age\").between(18, 24), \"18-24\")\n",
    "                                         .when(col(\"age\").between(25, 35), \"25-35\")\n",
    "                                         .when(col(\"age\").between(36, 50), \"36-50\")\n",
    "                                         .otherwise(\"50+\"))\n",
    "\n",
    "# Join the user DataFrame with the pin DataFrame on the index column\n",
    "df_combined = df_pin.join(df_user_age_grouped, df_pin.ind == df_user_age_grouped.ind)\n",
    "\n",
    "# Group by age group and calculate the median follower count for each age group\n",
    "df_median_follower_count = df_combined.groupBy(\"age_group\") \\\n",
    "    .agg(expr(\"percentile_approx(follower_count, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "# Display the result\n",
    "df_median_follower_count.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84205f74-4dcb-406b-8ed0-7199d7fb29c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 9: Find how many users have joined each year?\n",
    "Find how many users have joined between 2015 and 2020.\n",
    "\n",
    "Your query should return a DataFrame that contains the following columns:\n",
    "\n",
    "- post_year, a new column that contains only the year from the timestamp column\n",
    "- number_users_joined, a new column containing the desired query output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e03c34ae-5fc6-4f16-8e84-25b606acd1af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+-------------------+\n",
       "join_year|number_users_joined|\n",
       "+---------+-------------------+\n",
       "     2015|                 24|\n",
       "     2016|                 27|\n",
       "     2017|                  8|\n",
       "+---------+-------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---------+-------------------+\n|join_year|number_users_joined|\n+---------+-------------------+\n|     2015|                 24|\n|     2016|                 27|\n|     2017|                  8|\n+---------+-------------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, countDistinct\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "df_user_year = df_user.withColumn(\"join_year\", year(\"date_joined\"))\n",
    "\n",
    "# Filter the data for users who joined between 2015 and 2020\n",
    "df_filtered_users = df_user_year.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Group by the join year and count the distinct users\n",
    "df_number_users_joined = df_filtered_users.groupBy(\"join_year\").agg(countDistinct(\"user_name\").alias(\"number_users_joined\"))\n",
    "\n",
    "# Display the result\n",
    "df_number_users_joined.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "314e0734-aa19-4d1b-bb49-1786c8766df4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 10: Find the median follower count of users based on their joining year\n",
    "\n",
    "Find the median follower count of users have joined between 2015 and 2020.\n",
    "\n",
    "Your query should return a DataFrame that contains the following columns:\n",
    "\n",
    "- post_year, a new column that contains only the year from the timestamp column\n",
    "- median_follower_count, a new column containing the desired query output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6908e9dc-d820-4bad-ae55-79f864706fb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----+------------------+---+-------------------+---------+---------------------+\n",
       "  ind|         user_name|age|        date_joined|join_year|median_follower_count|\n",
       "+-----+------------------+---+-------------------+---------+---------------------+\n",
       " 5730|       RachelDavis| 36|2015-12-08 20:02:43|     2015|                   22|\n",
       " 2923|       BrianNelson| 26|2015-11-11 03:20:57|     2015|                   22|\n",
       "  857|       AndrewBurke| 20|2015-11-14 17:38:31|     2015|                   22|\n",
       " 7528|        AbigailAli| 20|2015-10-24 11:23:51|     2015|                   22|\n",
       " 4249|AlexandriaAlvarado| 20|2015-10-23 04:13:23|     2015|                   22|\n",
       " 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|     2015|                   22|\n",
       " 6063|      CoreyAndrews| 23|2015-11-25 13:36:22|     2015|                   22|\n",
       " 6145|      EmilyHawkins| 30|2015-12-25 20:24:37|     2015|                   22|\n",
       " 8304|      CharlesBerry| 25|2015-12-28 04:21:39|     2015|                   22|\n",
       " 3156|       AndrewBaker| 22|2015-12-21 08:06:54|     2015|                   22|\n",
       "  428|      ClaudiaAdams| 20|2015-11-28 02:20:29|     2015|                   22|\n",
       "10138|        CarolSilva| 22|2015-12-31 14:57:02|     2015|                   22|\n",
       " 7922|       DeniseAdams| 21|2015-11-12 06:21:36|     2015|                   22|\n",
       " 9875|     BrendanJoseph| 26|2015-12-20 10:28:00|     2015|                   22|\n",
       " 4315|    MichellePrince| 36|2015-12-20 16:38:13|     2015|                   22|\n",
       " 8237|       AaronAbbott| 20|2015-10-23 16:08:41|     2015|                   22|\n",
       " 3089|        AbigailAli| 20|2015-10-24 11:23:51|     2015|                   22|\n",
       " 5494|         AnneAllen| 27|2015-12-16 15:20:05|     2015|                   22|\n",
       "10883|       CarlHampton| 25|2015-11-26 03:43:03|     2015|                   22|\n",
       "10321|       AndreaBurke| 20|2015-12-12 11:20:08|     2015|                   22|\n",
       "+-----+------------------+---+-------------------+---------+---------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-----+------------------+---+-------------------+---------+---------------------+\n|  ind|         user_name|age|        date_joined|join_year|median_follower_count|\n+-----+------------------+---+-------------------+---------+---------------------+\n| 5730|       RachelDavis| 36|2015-12-08 20:02:43|     2015|                   22|\n| 2923|       BrianNelson| 26|2015-11-11 03:20:57|     2015|                   22|\n|  857|       AndrewBurke| 20|2015-11-14 17:38:31|     2015|                   22|\n| 7528|        AbigailAli| 20|2015-10-24 11:23:51|     2015|                   22|\n| 4249|AlexandriaAlvarado| 20|2015-10-23 04:13:23|     2015|                   22|\n| 8731|   AndreaAlexander| 21|2015-11-10 09:27:42|     2015|                   22|\n| 6063|      CoreyAndrews| 23|2015-11-25 13:36:22|     2015|                   22|\n| 6145|      EmilyHawkins| 30|2015-12-25 20:24:37|     2015|                   22|\n| 8304|      CharlesBerry| 25|2015-12-28 04:21:39|     2015|                   22|\n| 3156|       AndrewBaker| 22|2015-12-21 08:06:54|     2015|                   22|\n|  428|      ClaudiaAdams| 20|2015-11-28 02:20:29|     2015|                   22|\n|10138|        CarolSilva| 22|2015-12-31 14:57:02|     2015|                   22|\n| 7922|       DeniseAdams| 21|2015-11-12 06:21:36|     2015|                   22|\n| 9875|     BrendanJoseph| 26|2015-12-20 10:28:00|     2015|                   22|\n| 4315|    MichellePrince| 36|2015-12-20 16:38:13|     2015|                   22|\n| 8237|       AaronAbbott| 20|2015-10-23 16:08:41|     2015|                   22|\n| 3089|        AbigailAli| 20|2015-10-24 11:23:51|     2015|                   22|\n| 5494|         AnneAllen| 27|2015-12-16 15:20:05|     2015|                   22|\n|10883|       CarlHampton| 25|2015-11-26 03:43:03|     2015|                   22|\n|10321|       AndreaBurke| 20|2015-12-12 11:20:08|     2015|                   22|\n+-----+------------------+---+-------------------+---------+---------------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "df_user_year = df_user.withColumn(\"join_year\", year(\"date_joined\"))\n",
    "\n",
    "# Filter the data for users who joined between 2015 and 2020\n",
    "df_filtered_users = df_user_year.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Calculate the median follower count for each year\n",
    "windowSpec = Window.partitionBy(\"join_year\")\n",
    "df_median_follower_count = df_filtered_users.withColumn(\"median_follower_count\", F.expr(\"percentile_approx(age, 0.5)\").over(windowSpec)).distinct()\n",
    "\n",
    "# Display the result\n",
    "df_median_follower_count.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4613f262-afb9-4deb-9a6a-8dac6227c1e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 11: Find the median follower count of users based on their joining year and age group\n",
    "\n",
    "Find the median follower count of users that have joined between 2015 and 2020, based on which age group they are part of.\n",
    "Your query should return a DataFrame that contains the following columns:\n",
    "\n",
    "- age_group, a new column based on the original age column\n",
    "- post_year, a new column that contains only the year from the timestamp column\n",
    "- median_follower_count, a new column containing the desired query output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "409d19fe-46e4-4ea4-9e09-ad0c22a73e2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+---------+---------------------+\n",
       "age_group|post_year|median_follower_count|\n",
       "+---------+---------+---------------------+\n",
       "    20-29|     2015|                 7528|\n",
       "      40+|     2016|                 3813|\n",
       "    20-29|     2016|                 5069|\n",
       "    30-39|     2016|                 2863|\n",
       "    20-29|     2017|                 5091|\n",
       "    30-39|     2015|                 5730|\n",
       "      40+|     2017|                 1611|\n",
       "    30-39|     2017|                10625|\n",
       "+---------+---------+---------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---------+---------+---------------------+\n|age_group|post_year|median_follower_count|\n+---------+---------+---------------------+\n|    20-29|     2015|                 7528|\n|      40+|     2016|                 3813|\n|    20-29|     2016|                 5069|\n|    30-39|     2016|                 2863|\n|    20-29|     2017|                 5091|\n|    30-39|     2015|                 5730|\n|      40+|     2017|                 1611|\n|    30-39|     2017|                10625|\n+---------+---------+---------------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, expr, col\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "df_user_year = df_user.withColumn(\"join_year\", year(\"date_joined\"))\n",
    "\n",
    "# Filter the data for users who joined between 2015 and 2020\n",
    "df_filtered_users = df_user_year.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Calculate age group\n",
    "df_filtered_users = df_filtered_users.withColumn(\"age_group\", F.when(col(\"age\") < 20, \"0-19\")\n",
    "                                                     .when((col(\"age\") >= 20) & (col(\"age\") < 30), \"20-29\")\n",
    "                                                     .when((col(\"age\") >= 30) & (col(\"age\") < 40), \"30-39\")\n",
    "                                                     .otherwise(\"40+\"))\n",
    "\n",
    "# Group by age group, join year, and calculate the median follower count\n",
    "df_median_follower_count = df_filtered_users.groupBy(\"age_group\", \"join_year\") \\\n",
    "    .agg(expr(\"percentile_approx(ind, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "# Add a column for post_year containing only the year from the timestamp column\n",
    "df_median_follower_count = df_median_follower_count.withColumn(\"post_year\", col(\"join_year\"))\n",
    "\n",
    "# Reorder columns\n",
    "df_median_follower_count = df_median_follower_count.select(\"age_group\", \"post_year\", \"median_follower_count\")\n",
    "\n",
    "# Display the result\n",
    "df_median_follower_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d8be818-e533-4292-a607-3b29a63f45d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+---------------------+\n",
       "join_year|median_follower_count|\n",
       "+---------+---------------------+\n",
       "     2015|                 6145|\n",
       "     2016|                 4949|\n",
       "     2017|                 5091|\n",
       "+---------+---------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---------+---------------------+\n|join_year|median_follower_count|\n+---------+---------------------+\n|     2015|                 6145|\n|     2016|                 4949|\n|     2017|                 5091|\n+---------+---------------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, expr, col\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "df_user_year = df_user.withColumn(\"join_year\", year(\"date_joined\"))\n",
    "\n",
    "# Filter the data for users who joined between 2015 and 2020\n",
    "df_filtered_users = df_user_year.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Calculate age group\n",
    "#df_filtered_users = df_filtered_users.withColumn(\"age_group\", F.when(col(\"age\") < 20, \"0-19\")\n",
    "                                                     #.when((col(\"age\") >= 20) & (col(\"age\") < 30), #\"20-29\")\n",
    "                                                     #.when((col(\"age\") >= 30) & (col(\"age\") < 40), #\"30-39\")\n",
    "                                                     #.otherwise(\"40+\"))\n",
    "\n",
    "# Group by age group, join year, and calculate the median follower count\n",
    "df_median_follower_count = df_filtered_users.groupBy(\"join_year\") \\\n",
    "    .agg(expr(\"percentile_approx(ind, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "# Display the result\n",
    "df_median_follower_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5224eeb-f322-4ea9-901f-1d51f391387c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---------+---------+---------------------+\n",
       "age_group|join_year|median_follower_count|\n",
       "+---------+---------+---------------------+\n",
       "    30-39|     2016|                 2863|\n",
       "    20-29|     2015|                 7528|\n",
       "    30-39|     2015|                 5730|\n",
       "    20-29|     2016|                 5069|\n",
       "      40+|     2017|                 1611|\n",
       "    20-29|     2017|                 5091|\n",
       "      40+|     2016|                 3813|\n",
       "    30-39|     2017|                10625|\n",
       "+---------+---------+---------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+---------+---------+---------------------+\n|age_group|join_year|median_follower_count|\n+---------+---------+---------------------+\n|    30-39|     2016|                 2863|\n|    20-29|     2015|                 7528|\n|    30-39|     2015|                 5730|\n|    20-29|     2016|                 5069|\n|      40+|     2017|                 1611|\n|    20-29|     2017|                 5091|\n|      40+|     2016|                 3813|\n|    30-39|     2017|                10625|\n+---------+---------+---------------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, expr, col\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "df_user_year = df_user.withColumn(\"join_year\", year(\"date_joined\"))\n",
    "\n",
    "# Filter the data for users who joined between 2015 and 2020\n",
    "df_filtered_users = df_user_year.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Calculate age group\n",
    "df_filtered_users = df_filtered_users.withColumn(\"age_group\", F.when(col(\"age\") < 20, \"0-19\")\n",
    "                                                     .when((col(\"age\") >= 20) & (col(\"age\") < 30), \"20-29\")\n",
    "                                                     .when((col(\"age\") >= 30) & (col(\"age\") < 40), \"30-39\")\n",
    "                                                     .otherwise(\"40+\"))\n",
    "\n",
    "# Group by age group, join year, and calculate the median follower count\n",
    "df_median_follower_count = df_filtered_users.groupBy(\"age_group\", \"join_year\") \\\n",
    "    .agg(expr(\"percentile_approx(ind, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "# Display the result\n",
    "df_median_follower_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b1f9816-5c05-4b62-8ffd-ac5e490714fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">DataFrame[ind: bigint, user_name: string, age: bigint, date_joined: timestamp, join_year: int, age_group: string]\n",
       "DataFrame[ind: bigint, follower_count: int]\n",
       "[&#39;ind&#39;, &#39;follower_count&#39;]\n",
       "[&#39;ind&#39;, &#39;follower_count&#39;]\n",
       "DataFrame[ind: bigint, user_name: string, age: bigint, date_joined: timestamp, join_year: int, age_group: string]\n",
       "DataFrame[ind: bigint, follower_count: int]\n",
       "+---------+---------+---------------------+\n",
       "age_group|join_year|median_follower_count|\n",
       "+---------+---------+---------------------+\n",
       "    18-24|     2015|               211000|\n",
       "    25-35|     2015|                51000|\n",
       "    36-50|     2015|                    0|\n",
       "    18-24|     2016|               502000|\n",
       "    25-35|     2016|                43000|\n",
       "    36-50|     2016|                17000|\n",
       "      50+|     2016|                  908|\n",
       "    18-24|     2017|                  940|\n",
       "    25-35|     2017|                 8000|\n",
       "    36-50|     2017|                 6000|\n",
       "+---------+---------+---------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">DataFrame[ind: bigint, user_name: string, age: bigint, date_joined: timestamp, join_year: int, age_group: string]\nDataFrame[ind: bigint, follower_count: int]\n[&#39;ind&#39;, &#39;follower_count&#39;]\n[&#39;ind&#39;, &#39;follower_count&#39;]\nDataFrame[ind: bigint, user_name: string, age: bigint, date_joined: timestamp, join_year: int, age_group: string]\nDataFrame[ind: bigint, follower_count: int]\n+---------+---------+---------------------+\n|age_group|join_year|median_follower_count|\n+---------+---------+---------------------+\n|    18-24|     2015|               211000|\n|    25-35|     2015|                51000|\n|    36-50|     2015|                    0|\n|    18-24|     2016|               502000|\n|    25-35|     2016|                43000|\n|    36-50|     2016|                17000|\n|      50+|     2016|                  908|\n|    18-24|     2017|                  940|\n|    25-35|     2017|                 8000|\n|    36-50|     2017|                 6000|\n+---------+---------+---------------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Assuming follower information is contained within df_pin, you can filter the relevant columns\n",
    "df_followers = df_pin.select(\"ind\", \"follower_count\")\n",
    "\n",
    "# Now you have a DataFrame df_followers containing the unique_id and follower_count columns\n",
    "\n",
    "\n",
    "# Assuming df_followers is properly defined and contains the necessary columns\n",
    "# Join df_filtered_users with df_followers on a common key (e.g., unique_id)\n",
    "print(df_filtered_users)\n",
    "print(df_followers)\n",
    "print(df_followers.columns)  # This line is causing the error\n",
    "\n",
    "# Correcting the error: Accessing the columns attribute of df_followers\n",
    "print(df_followers.columns)\n",
    "\n",
    "\n",
    "df_filtered_users_with_followers = df_filtered_users.join(df_followers, df_filtered_users[\"ind\"] == df_followers[\"ind\"], how=\"inner\")\n",
    "print(df_filtered_users)\n",
    "print(df_followers)\n",
    "# Once the join is successful, you can proceed with the rest of the code to calculate the median follower count\n",
    "\n",
    "# Calculate the median follower count for each year and age group\n",
    "windowSpec = Window.partitionBy(\"join_year\", \"age_group\")\n",
    "df_median_follower_count = df_filtered_users_with_followers.withColumn(\n",
    "    \"median_follower_count\",\n",
    "    expr(\"percentile_approx(follower_count, 0.5)\").over(windowSpec)\n",
    ").select(\"age_group\", \"join_year\", \"median_follower_count\").distinct()\n",
    "\n",
    "# Display the result\n",
    "df_median_follower_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16239ad8-b79c-4edb-90fd-ed01696da4f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">DataFrame[ind: bigint, user_name: string, age: bigint, date_joined: timestamp, join_year: int, age_group: string]\n",
       "DataFrame[ind: bigint, follower_count: int]\n",
       "[&#39;ind&#39;, &#39;follower_count&#39;]\n",
       "[&#39;ind&#39;, &#39;follower_count&#39;]\n",
       "DataFrame[ind: bigint, user_name: string, age: bigint, date_joined: timestamp, join_year: int, age_group: string]\n",
       "DataFrame[ind: bigint, follower_count: int]\n",
       "+---------+---------+---------------------+\n",
       "age_group|join_year|median_follower_count|\n",
       "+---------+---------+---------------------+\n",
       "    18-24|     2015|               211000|\n",
       "    25-35|     2015|                51000|\n",
       "    36-50|     2015|                    0|\n",
       "    18-24|     2016|               502000|\n",
       "    25-35|     2016|                43000|\n",
       "    36-50|     2016|                17000|\n",
       "      50+|     2016|                  908|\n",
       "    18-24|     2017|                  940|\n",
       "    25-35|     2017|                 8000|\n",
       "    36-50|     2017|                 6000|\n",
       "+---------+---------+---------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">DataFrame[ind: bigint, user_name: string, age: bigint, date_joined: timestamp, join_year: int, age_group: string]\nDataFrame[ind: bigint, follower_count: int]\n[&#39;ind&#39;, &#39;follower_count&#39;]\n[&#39;ind&#39;, &#39;follower_count&#39;]\nDataFrame[ind: bigint, user_name: string, age: bigint, date_joined: timestamp, join_year: int, age_group: string]\nDataFrame[ind: bigint, follower_count: int]\n+---------+---------+---------------------+\n|age_group|join_year|median_follower_count|\n+---------+---------+---------------------+\n|    18-24|     2015|               211000|\n|    25-35|     2015|                51000|\n|    36-50|     2015|                    0|\n|    18-24|     2016|               502000|\n|    25-35|     2016|                43000|\n|    36-50|     2016|                17000|\n|      50+|     2016|                  908|\n|    18-24|     2017|                  940|\n|    25-35|     2017|                 8000|\n|    36-50|     2017|                 6000|\n+---------+---------+---------------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming df_followers is properly defined and contains the necessary columns\n",
    "# Join df_filtered_users with df_followers on a common key (e.g., unique_id)\n",
    "print(df_filtered_users)\n",
    "print(df_followers)\n",
    "print(df_followers.columns)  # This line is causing the error\n",
    "\n",
    "# Correcting the error: Accessing the columns attribute of df_followers\n",
    "print(df_followers.columns)\n",
    "\n",
    "df_filtered_users_with_followers = df_filtered_users.join(df_followers, df_filtered_users[\"ind\"] == df_followers[\"ind\"], how=\"inner\")\n",
    "print(df_filtered_users)\n",
    "print(df_followers)\n",
    "# Once the join is successful, you can proceed with the rest of the code to calculate the median follower count\n",
    "\n",
    "# Calculate the median follower count for each year and age group\n",
    "windowSpec = Window.partitionBy(\"join_year\", \"age_group\")\n",
    "df_median_follower_count = df_filtered_users_with_followers.withColumn(\n",
    "    \"median_follower_count\",\n",
    "    expr(\"percentile_approx(follower_count, 0.5)\").over(windowSpec)\n",
    ").select(\"age_group\", \"join_year\", \"median_follower_count\").distinct()\n",
    "\n",
    "# Display the result\n",
    "df_median_follower_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "679eed07-8505-4a6c-ae2e-8bb6cca80e22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">DataFrame[ind: bigint, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string]\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">DataFrame[ind: bigint, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string]\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4f2a622-6227-4249-b805-a0d66157215a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d6e15a7-0d00-450a-b4c3-bace8717c31f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0fe54c0-c081-438b-83ec-47f765df6c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0edb3d40-0798-43f7-9fc4-cd35b1a276f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c0aab08-bed5-485e-81fd-c8d23f5a37cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----+---------------+---+-------------------+---------+---------------------+\n",
       "  ind|      user_name|age|        date_joined|join_year|median_follower_count|\n",
       "+-----+---------------+---+-------------------+---------+---------------------+\n",
       " 4315| MichellePrince| 36|2015-12-20 16:38:13|     2015|                   22|\n",
       " 3089|     AbigailAli| 20|2015-10-24 11:23:51|     2015|                   22|\n",
       " 7528|     AbigailAli| 20|2015-10-24 11:23:51|     2015|                   22|\n",
       " 5494|      AnneAllen| 27|2015-12-16 15:20:05|     2015|                   22|\n",
       " 9875|  BrendanJoseph| 26|2015-12-20 10:28:00|     2015|                   22|\n",
       " 8304|   CharlesBerry| 25|2015-12-28 04:21:39|     2015|                   22|\n",
       " 9270|       AmyBrown| 21|2015-11-08 16:14:16|     2015|                   22|\n",
       "    4|     AdamAcosta| 20|2015-10-21 21:26:45|     2015|                   22|\n",
       "10029|   AnthonyBaker| 20|2015-11-14 19:24:56|     2015|                   22|\n",
       " 1667|  BernardArnold| 21|2015-12-12 01:39:29|     2015|                   22|\n",
       " 5730|    RachelDavis| 36|2015-12-08 20:02:43|     2015|                   22|\n",
       " 2923|    BrianNelson| 26|2015-11-11 03:20:57|     2015|                   22|\n",
       " 2418|    AmandaAdams| 20|2015-10-21 08:27:36|     2015|                   22|\n",
       "  857|    AndrewBurke| 20|2015-11-14 17:38:31|     2015|                   22|\n",
       " 6063|   CoreyAndrews| 23|2015-11-25 13:36:22|     2015|                   22|\n",
       " 6145|   EmilyHawkins| 30|2015-12-25 20:24:37|     2015|                   22|\n",
       " 8731|AndreaAlexander| 21|2015-11-10 09:27:42|     2015|                   22|\n",
       " 8237|    AaronAbbott| 20|2015-10-23 16:08:41|     2015|                   22|\n",
       " 3156|    AndrewBaker| 22|2015-12-21 08:06:54|     2015|                   22|\n",
       "  428|   ClaudiaAdams| 20|2015-11-28 02:20:29|     2015|                   22|\n",
       "+-----+---------------+---+-------------------+---------+---------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-----+---------------+---+-------------------+---------+---------------------+\n|  ind|      user_name|age|        date_joined|join_year|median_follower_count|\n+-----+---------------+---+-------------------+---------+---------------------+\n| 4315| MichellePrince| 36|2015-12-20 16:38:13|     2015|                   22|\n| 3089|     AbigailAli| 20|2015-10-24 11:23:51|     2015|                   22|\n| 7528|     AbigailAli| 20|2015-10-24 11:23:51|     2015|                   22|\n| 5494|      AnneAllen| 27|2015-12-16 15:20:05|     2015|                   22|\n| 9875|  BrendanJoseph| 26|2015-12-20 10:28:00|     2015|                   22|\n| 8304|   CharlesBerry| 25|2015-12-28 04:21:39|     2015|                   22|\n| 9270|       AmyBrown| 21|2015-11-08 16:14:16|     2015|                   22|\n|    4|     AdamAcosta| 20|2015-10-21 21:26:45|     2015|                   22|\n|10029|   AnthonyBaker| 20|2015-11-14 19:24:56|     2015|                   22|\n| 1667|  BernardArnold| 21|2015-12-12 01:39:29|     2015|                   22|\n| 5730|    RachelDavis| 36|2015-12-08 20:02:43|     2015|                   22|\n| 2923|    BrianNelson| 26|2015-11-11 03:20:57|     2015|                   22|\n| 2418|    AmandaAdams| 20|2015-10-21 08:27:36|     2015|                   22|\n|  857|    AndrewBurke| 20|2015-11-14 17:38:31|     2015|                   22|\n| 6063|   CoreyAndrews| 23|2015-11-25 13:36:22|     2015|                   22|\n| 6145|   EmilyHawkins| 30|2015-12-25 20:24:37|     2015|                   22|\n| 8731|AndreaAlexander| 21|2015-11-10 09:27:42|     2015|                   22|\n| 8237|    AaronAbbott| 20|2015-10-23 16:08:41|     2015|                   22|\n| 3156|    AndrewBaker| 22|2015-12-21 08:06:54|     2015|                   22|\n|  428|   ClaudiaAdams| 20|2015-11-28 02:20:29|     2015|                   22|\n+-----+---------------+---+-------------------+---------+---------------------+\nonly showing top 20 rows\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Extract the year from the date_joined column\n",
    "df_user_year = df_user.withColumn(\"join_year\", year(\"date_joined\"))\n",
    "\n",
    "# Filter the data for users who joined between 2015 and 2020\n",
    "df_filtered_users = df_user_year.filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020))\n",
    "\n",
    "# Calculate the median follower count for each year\n",
    "windowSpec = Window.partitionBy(\"join_year\")\n",
    "df_median_follower_count = df_filtered_users.withColumn(\"median_follower_count\", F.expr(\"percentile_approx(age, 0.5)\").over(windowSpec)).distinct()\n",
    "\n",
    "# Display the result\n",
    "df_median_follower_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "259b6512-fd80-4c82-bdcc-05623f9a5092",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1034de8b-a913-4865-9d0b-1fb7a7da7131",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "822cb0c2-7c33-4104-963f-f4b0cd0170b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9ad4ad7-7024-4300-a2f4-ca40fb3bfa1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9b4a617-6a6d-4b43-ba0e-d99274446b46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5102f021-f41d-4c09-9361-1b8c611db647",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "2f156265-5c26-45b6-8786-4a4d40529d2c",
     "origId": 1102316484775152,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clean-cataframe-pinterest-posts",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
